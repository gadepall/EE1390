# Speech-Command-Model

## Requirements
pip install sklearn
Kapre == 0.1.7
Tensorflow-gpu == 2.2.0
Soundfile

## Local Run
#Download the Repository.
git clone https://github.com/PradeepMoturi/Speech-Command-Model
#Open terminal and change directory to Src.
cd Src
#Check the data_dir in DataGenerator.py which is currently pointing to ../Data/Pradeep_16.     Change it to the directory of your data(in mentioned format) if needed.
nano DataGenerator.py
#
4.  Change 3rd argument to range in line 31 and 47 to change number of values to shift.
    This also controls memory used. Increase it if you face out of memory error.
5.  Run the below line
    ```
    python3 DataGenerator.py
    ```
6.  This reads the audio files in data_dir and creates files x_train.npy, y_train.npy, x_test.npy, y_test.npy in the provided data_dir.
7.  Check the data_dir in FeatureExtractor.py which is currently pointing to ../Data/Pradeep_16.
    Change it to the directory of your data if needed.
8.  Run the below line
    ```
    python3 FeatureExtractor.py
    ```
9.  This reads from files created by DataGenerator.py and creates files mfcc_train.npy, mfcc_test.npy in the provided data_dir.
10. Check the data_dir in TrainModel.py which is currently pointing to ../Data/Pradeep_16.
    Change it to the directory of your data if needed.
11. You can change batch_size and epochs accordingly to fit in VRAM.
12. Run the below line
    ```
    python3 TrainModel.py
    ```
13. This reads the files generated by FeatureExtractor.py and trains the attention model.
14. The trained model will be saved as model.h5

## Colab Run
1.  ColabNotebook.ipynb to your Google Drive
2.  Open ColabNotebook.ipynb and change Runtime to GPU
3.  Do either of 
    1.  Upload Data/Pradeep_16 to your drive and Mount your drive. (All files will be saved for future runs)
    2.  Upload Data/Pradeep_16 to Colab. (All files will be deleted after the session expires)
4.  Change data_dir in all cells to point to Pradeep_16
5.  Run the cells in the same order in Notebook.

## Documentation
Please read Report.pdf for further information.
